import os
import re
import spacy
from collections import Counter
from spacy.lang.fr.stop_words import STOP_WORDS

# Installation de spaCy si n√©cessaire
try:
    nlp = spacy.load("fr_core_news_md")
except:
    import subprocess
    subprocess.run(["python", "-m", "spacy", "download", "fr_core_news_md"])
    nlp = spacy.load("fr_core_news_md")

# Chemin vers le dossier contenant les notes Obsidian
NOTES_FOLDER = "/Users/sodaa/Documents/temp_notes_zotero"

# Liste compl√®te des concepts existants √† EXCLURE
CONCEPTS_LIST = [
    "immanence", "biopolitique", "rhizome", "√©pist√©mologie", "ontologie",
    "capitalisme", "destitution", "r√©volution", "communisme", "affect", "affection", 
    "police", "soci√©t√©", "√©conomie", "√©meute", "forme", "institution", "insurrection", 
    "n√©olib√©ral", "peuple", "r√©el", "agencement", "anarchiste", "capital", "civilisation", 
    "langage", "classes", "conatus", "pulsion", "contr√¥le", "imitation", "corps", "d√©mocratie", 
    "d√©sir", "imagination", "individu", "joie", "justice", "l√©gitimit√©", "politique", 
    "populisme", "pouvoir", "puissance", "relation", "sabotage", "travail", "usage", "amour", 
    "artiste", "attentat", "autochtone", "autonome", "autre", "banlieue", "catastrophe", "commun", 
    "communaut√©", "communisme", "commune", "communication", "complot", "conflit", "consentement", 
    "contrainte", "critique", "cybern√©tique", "d√©sastre", "d√©terminisme", "dette", "division du travail", 
    "√©chelle", "espoir", "√©v√®nement", "√©tendue", "pens√©e", "fragmentation", "genre", "gouverner", 
    "h√©t√©ronomie", "horizontalit√©", "information", "ingouvernable", "libertaire", "liens", "masse", 
    "militant", "militer", "mobilisation", "obs√©quium", "imperium", "panoptique", "r√©publique", 
    "rencontre", "situation", "souverainet√©", "spectacle", "structure", "surveillance", "technologie", 
    "technique", "temps", "transindividuel", "utopie", "tristesse"
]

# Dictionnaire pour stocker les concepts et leur fr√©quence
concepts_counter = Counter()

# Fonction pour nettoyer et extraire le contenu sans m√©tadonn√©es YAML
def extract_content(content):
    yaml_pattern = re.compile(r"^---\n(.*?)\n---", re.DOTALL)
    content = re.sub(yaml_pattern, "", content).strip()
    return content

# Fonction pour extraire les concepts potentiels
def detect_concepts(text):
    doc = nlp(text)
    keywords = [token.text.lower() for token in doc if token.is_alpha and token.text.lower() not in STOP_WORDS]
    keyword_freq = Counter(keywords)

    # Ajouter les concepts r√©currents non list√©s dans CONCEPTS_LIST
    for keyword, freq in keyword_freq.items():
        if keyword not in CONCEPTS_LIST and freq >= 5:  # Ajuster la fr√©quence pour limiter le bruit
            concepts_counter[keyword] += freq

# Fonction principale
def analyze_all_notes():
    for root, _, files in os.walk(NOTES_FOLDER):
        for file in files:
            if file.endswith(".md"):
                file_path = os.path.join(root, file)
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()

                text_content = extract_content(content)
                detect_concepts(text_content)

    # G√©n√©rer les 200 concepts les plus pertinents
    top_concepts = concepts_counter.most_common(200)

    with open(os.path.join(NOTES_FOLDER, "concepts_propos√©s.md"), "w", encoding="utf-8") as f:
        f.write("# Concepts propos√©s pour validation (200 max)\n\n")
        for concept, freq in top_concepts:
            f.write(f"- {concept} (fr√©quence : {freq})\n")

    print("\n‚úÖ Fichier 'concepts_propos√©s.md' cr√©√© avec succ√®s !")

if __name__ == "__main__":
    print("üîç Analyse de l'ensemble de tes notes en cours...")
    analyze_all_notes()
    print("‚úÖ Analyse termin√©e ! V√©rifie le fichier `concepts_propos√©s.md`")
